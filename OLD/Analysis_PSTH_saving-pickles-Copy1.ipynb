{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['fft', 'log10', 'power', 'sqrt', 'arccos', 'linalg', 'arctanh', 'show_config', 'copy', '__version__', 'arcsin', 'log2', 'log', 'test']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    " %pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from scipy import *\n",
    "from scipy import stats, io\n",
    "import numpy as np\n",
    "import struct\n",
    "import tables as tb\n",
    "from attrdict import AttrDict\n",
    "import matplotlib.pyplot as plt\n",
    "import os as os\n",
    "from phy.io import KwikModel\n",
    "import codecs as codecs\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "#SAVING BINARY OBJECTS DATA\n",
    "#need to automate data folder creation\n",
    "#----------------------------------------------------------------------------------------\n",
    "import pickle \n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open( name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open( name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16599.77, 31600.17, 103599.8, 154599.7, 231099.57, 78099.83, 78099.83]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------------------------------------------------\n",
    "# GET STIMTIMES\n",
    "#---------------------------------------------------------\n",
    "def get_ep_duration(eptimefile):\n",
    "    \n",
    "    eptimesf = open(eptimefile, 'r')\n",
    "    eptimes = [float(x)/30 for x in eptimesf.read().split()]\n",
    "    eptimesf.close()\n",
    "   \n",
    "    return eptimes\n",
    "    \n",
    "    \n",
    "    \n",
    "file = '/media/matias/DATA/WORKSPACE2/EXP_1/ep_times.txt'\n",
    "ep_t1 = get_ep_times(file)\n",
    "file = '/media/matias/DATA/WORKSPACE2/EXP_2/ep_times.txt'\n",
    "ep_t2 = get_ep_times(file)\n",
    "[round(v,2) for v in ep_t2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.07', '1001.63', '2001.60', '3001.53', '5501.37', '8001.23', '10501.07', '13000.93', '15500.77', '20500.60', '25500.40', '28000.23', '29000.17', '33999.97', '34999.93', '35999.87', '38499.70', '39499.67', '44499.47', '45499.40', '47999.23', '52999.03', '57998.87', '62998.67', '67998.47', '68998.40', '69998.33', '74998.13']\n"
     ]
    }
   ],
   "source": [
    "print([\"%.2f\" % v for v in Stims.st_times[0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS TO BUILD PSTHs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------\n",
    "# GET EPDURATION\n",
    "#---------------------------------------------------------\n",
    "def get_ep_duration(eptimefile):\n",
    "    \n",
    "    eptimesf = open(eptimefile, 'r')\n",
    "    eptimes = [float(x)/30 for x in eptimesf.read().split()]\n",
    "    eptimesf.close()\n",
    "   \n",
    "    return eptimes\n",
    "\n",
    "#---------------------------------------------------------\n",
    "# BUILD DICT STIM, reads stims and times of .txt files of experiments\n",
    "#---------------------------------------------------------\n",
    "def build_dict_stim(stimfile, timefile, epdurationfile):\n",
    "\n",
    "    stims, times = get_stimtimes(stimfile,timefile)\n",
    "    #------------------------------------------\n",
    "    # count number of episodes\n",
    "    episodes=1\n",
    "    stims_ep=0\n",
    "    for time in times[:-1]:             #last line is blank, we skip it\n",
    "        if time == '': \n",
    "            episodes+=1\n",
    "        if episodes ==1:\n",
    "            stims_ep+=1\n",
    "    print('Total episodes: ', episodes)        \n",
    "    print('Total stims per episode: ', stims_ep)        \n",
    "    #------------------------------------------\n",
    "    # get episode duration\n",
    "    ep_duration = get_ep_duration(epdurationfile)\n",
    "    ####\n",
    "    # for the formatting I have now:           #####################X   XXXXXXXXXXXXXXXXXX\n",
    "    ep_length = ep_duration[6]\n",
    "    \n",
    "    ###\n",
    "    #------------------------------------------\n",
    "    # starting times of each stimulus\n",
    "    starts = np.zeros([episodes, stims_ep])\n",
    "    tot_stims = episodes*stims_ep\n",
    "\n",
    "    st_count=0\n",
    "    for t in times[:-1]:\n",
    "        if t!='':\n",
    "            st = st_count % stims_ep\n",
    "            ep = st_count // stims_ep \n",
    "            starts[ep,st] = t + ep*ep_length\n",
    "            st_count+=1\n",
    "    #------------------------------------------\n",
    "    # stims        \n",
    "    st_pad = zeros([episodes,stims_ep]) # 1 row, 2 arc, 3 pad\n",
    "    st_type = zeros([episodes,stims_ep]) # 1 hold, 2 pass, 3 release        \n",
    "    st_isi = zeros([episodes,stims_ep]) # 10 , 20, 50\n",
    "    st_rep = zeros([episodes,stims_ep]) # 2, 5, 10\n",
    "    st_ctrl = zeros([episodes,stims_ep]) # 0, blank, 1 ctrl1, 2 ctrl2, 3 ctrl3, 10 normal \n",
    "    # dictionary of stims\n",
    "    st_logic = {} \n",
    "    st_logic['pad'] = {'ROW' : 1, 'ARC' : 2, 'PAD' : 3}\n",
    "    st_logic['types'] = {'hold' : 1, 'pass' : 2, 'release' : 3}\n",
    "    st_logic['ctrl'] = {'BLANK' : 0, 'Ctrl1' : 1, 'Ctrl2' : 2, 'Ctrl3' : 3, 'Normal' : 10}\n",
    "\n",
    "    ep=0\n",
    "    st=0\n",
    "    # get stims\n",
    "    for stim in stims[:-3]:           #last three lines useless\n",
    "        line = stim.split()\n",
    "        if line and ep<episodes:\n",
    "\n",
    "            if line[1]=='BLANK':\n",
    "                st+=1\n",
    "                if st%stims_ep==0:\n",
    "                    st=0\n",
    "                    ep+=1\n",
    "            elif len(line)>3:\n",
    "                if line[1][1:4]=='ROW': st_pad[ep,st]=1\n",
    "                elif line[1][1:4]=='ARC': st_pad[ep,st]=2\n",
    "                elif line[1][1:4]=='PAD': st_pad[ep,st]=3\n",
    "\n",
    "                if line[1][5:-1]=='Hold': st_type[ep,st]=1\n",
    "                elif line[1][5:-1]=='Pass': st_type[ep,st]=2\n",
    "                elif line[1][5:-1]=='Release': st_type[ep,st]=3\n",
    "\n",
    "                if line[3]=='REP_2': st_rep[ep,st]=2\n",
    "                elif line[3]=='REP_5': st_rep[ep,st]=5\n",
    "                elif line[3]=='REP_10': st_rep[ep,st]=10\n",
    "\n",
    "                if line[5]=='ISI_10': st_isi[ep,st]=10\n",
    "                elif line[5]=='ISI_20': st_isi[ep,st]=20\n",
    "                elif line[5]=='ISI_50': st_isi[ep,st]=50\n",
    "                    \n",
    "                if line[7]=='Normal': st_ctrl[ep,st]=10\n",
    "                elif line[7][0:5]=='Ctrl1': st_ctrl[ep,st]=1\n",
    "                elif line[7][0:5]=='Ctrl2': st_ctrl[ep,st]=2\n",
    "                elif line[7][0:5]=='Ctrl3': st_ctrl[ep,st]=3\n",
    "                elif line[7][0:5]=='Ctrl4': st_ctrl[ep,st]=4\n",
    "\n",
    "                st+=1\n",
    "                if st%stims_ep==0:\n",
    "                    st=0\n",
    "                    ep+=1\n",
    "\n",
    "    Stim_dict = AttrDict({'st_logic':st_logic, 'episodes': episodes  ,'stims_ep':stims_ep  ,'st_times': starts})\n",
    "    Stim_dict.update({'st_isi':st_isi,'st_rep':st_rep,'st_type':st_type,'st_ctrl': st_ctrl,'st_pad':st_pad})\n",
    "    \n",
    "    return Stim_dict\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# BUILD HIST DICTIONARY\n",
    "#----------------------------------------------------------------------------------------\n",
    "import copy as cp\n",
    "\n",
    "def build_hist_dict():\n",
    "    isis = [10,20,50]\n",
    "    reps = [2,5,10]\n",
    "    pads = ['arc','row','pad']\n",
    "    types = ['hold','pas','release']\n",
    "    \n",
    "    Isis ={}\n",
    "    for i in isis:\n",
    "        Isis[i]= []\n",
    "    \n",
    "    Reps ={}\n",
    "    for r in reps:\n",
    "        Reps[r] = cp.deepcopy(Isis)\n",
    "    \n",
    "    Pads = {}\n",
    "    for p in pads:\n",
    "        Pads[p] = cp.deepcopy(Reps)\n",
    "    \n",
    "    Types = {}\n",
    "    for t in types:\n",
    "        Types[t] = cp.deepcopy(Pads)\n",
    "    \n",
    "    Normal = cp.deepcopy(Types)\n",
    "    Ctrl1 = cp.deepcopy(Types)\n",
    "    Ctrl2 = cp.deepcopy(Types)\n",
    "    Ctrl3 = cp.deepcopy(Types)\n",
    "    Ctrl4 = cp.deepcopy(Types)\n",
    "    \n",
    "    counts_n = cp.deepcopy(Normal)\n",
    "    counts_c1 = cp.deepcopy(Normal)\n",
    "    counts_c2 = cp.deepcopy(Normal)\n",
    "    counts_c3 = cp.deepcopy(Normal)\n",
    "    counts_c4 = cp.deepcopy(Normal)\n",
    "    \n",
    "    Counts ={}\n",
    "    Counts['Normal'] = counts_n\n",
    "    Counts['Ctrl1'] = counts_c1\n",
    "    Counts['Ctrl2'] = counts_c2\n",
    "    Counts['Ctrl3'] = counts_c3\n",
    "    Counts['Ctrl4'] = counts_c4\n",
    "    Counts['Blank'] = []\n",
    "    \n",
    "    hist_logic = 'Type x Pad x Rep x Isi'\n",
    "    hist = AttrDict({ 'Blank' :[],  'Normal': Normal, 'Ctrl1':Ctrl1 , 'Ctrl2':Ctrl2 , 'Ctrl3': Ctrl3, 'Ctrl4': Ctrl4 , 'hist_logic': hist_logic, 'Counts':Counts})\n",
    "\n",
    "    return hist\n",
    "    \n",
    "#----------------------------------------------------------------------------------------\n",
    "# READKWIKINFO\n",
    "#----------------------------------------------------------------------------------------\n",
    "# We read the data of the output from klusterkwik: spike times and cluster-number of each\n",
    "# cluster-number is in klustaviewa series (can be as high as 130 e.g.)\n",
    "# Grupete stands for cluster groups! 2: good clusters, 1: multiunits, 0: unsorted, 3: noise\n",
    "def readkwikinfo(kwik, grupete=2):\n",
    "    model = KwikModel(kwik) # load kwik model from file\n",
    "    spiketimes = model.spike_times # extract the absolute spike times\n",
    "    clusters = model.cluster_groups # extract the cluster names\n",
    "    sample_rate = model.sample_rate # extract sampling freq\n",
    "    \n",
    "    spikedata = {} # initialise dictionary\n",
    "    for cluster in clusters.keys():\n",
    "        clustergroup = clusters[cluster]\n",
    "        if clustergroup==grupete: # only look at specified type of cluster, 0 = noise, 1 = MUA, 2 = GOOD, 3 = unsorted\n",
    "            spiketimematrix = AttrDict({'spike_times': np.zeros(len(spiketimes[where(model.spike_clusters==cluster)]))})\n",
    "            spiketimematrix.spike_times = spiketimes[where(model.spike_clusters==cluster)]\n",
    "            spikedata[cluster] = spiketimematrix # data structure is a dictionary with attribute accessible spiketimes\n",
    "            # attribute accessible means that spikedata.spike_times works, normal dictionaries would be spikedata[spike_times]\n",
    "    \n",
    "    model.close()\n",
    "    \n",
    "    return spikedata, sample_rate\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# BUILDS PSTH\n",
    "#----------------------------------------------------------------------------------------\n",
    "def BuildPSTH(Stims, Spikes, sampling_freq, exp, meas):\n",
    "    \n",
    "    stimtimes = {}\n",
    "    stim_samp = 1/.0009997575757\n",
    "    # make an 'output dict'\n",
    "    # the PSTH will be built on -tbefore:tafter\n",
    "    PSTH_times = {}\n",
    "    \n",
    "    # Loop each neuron and get the spikes.\n",
    "    for neuron in list(Spikes.keys()): \n",
    "        codename = 'exp'+ str(exp) + '_' + str(meas) + '_c' + str(neuron)\n",
    "        psth = AttrDict({'clusnum': neuron,'exp' : int(exp) , 'meas': int(meas[1]) , 'shank': int(meas[3])})\n",
    "        psth.update(AttrDict({'psth_counts': [] , 'psth_times': []}))\n",
    "        \n",
    "        hist= build_hist_dict()\n",
    "        \n",
    "        #loop episodes and stims_per_episode, and populate the histograms\n",
    "        for ep in arange(Stim.episodes):\n",
    "            for se in arange(Stim.stims_ep):\n",
    "                c = Stims.st_ctrl[ep][se]\n",
    "                t = Stims.st_type[ep][se]\n",
    "                p = Stims.st_pad[ep][se]\n",
    "                r = Stims.st_rep[ep][se]\n",
    "                i = Stims.st_isi[ep][se]\n",
    "                start = Stims.st_times[ep][se]\n",
    "                if c=='Blank':\n",
    "                    t_after=0.5\n",
    "                    hist[c].append (Spikes[(start <= spikes) * (spikes <= times + t_after)])\n",
    "                    hist['Counts'][c] += len(Spikes[(start <= spikes) * (spikes <= times + t_after)])\n",
    "                else:\n",
    "                    t_after = 0.5*r\n",
    "                    hist[c][t][p][r][i].append(Spikes[(start <= spikes) * (spikes <= times + t_after)])\n",
    "                    hist['Counts'][c][t][p][r][i] += lenSpikes([(start <= spikes) * (spikes <= times + t_after)])\n",
    "                                                       \n",
    "        PSTH_times[codename] = hist\n",
    "       \n",
    "    return PSTH_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total episodes:  15\n",
      "Total stims per episode:  28\n",
      "dict_keys(['st_isi', 'episodes', 'st_rep', 'st_times', 'st_ctrl', 'st_type', 'stims_ep', 'st_pad', 'st_logic'])\n",
      "dict_keys(['Blank', 'Ctrl1', 'hist_logic', 'Ctrl2', 'Normal', 'Ctrl3', 'Ctrl4', 'Counts'])\n",
      "Type x Pad x Rep x Isi\n",
      "AttrDict({'types': {'pass': 2, 'hold': 1, 'release': 3}, 'pad': {'PAD': 3, 'ROW': 1, 'ARC': 2}, 'ctrl': {'Normal': 10, 'BLANK': 0, 'Ctrl2': 2, 'Ctrl1': 1, 'Ctrl3': 3}})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 28)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Folder = '/media/matias/DATA/WORKSPACE2/EXP_2'        \n",
    "stimfile = Folder +'/EXPECT-151217-stims-7.txt'   \n",
    "timefile = Folder +'/EXPECT-151217-times-7.txt'   \n",
    "\n",
    "Stims = build_dict_stim(stimfile, timefile)\n",
    "\n",
    "print(Stims.keys())\n",
    "\n",
    "h = build_hist_dict()\n",
    "\n",
    "print(h.keys())\n",
    "print(h.hist_logic)\n",
    "\n",
    "print(Stims.st_logic)\n",
    "\n",
    "Stims.st_rep.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Files and Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this cell you put all the information to make the code portable from computer to computer\n",
    "# You have to place all the file names and experiments, then you loop whichever you want to analyse\n",
    "#--------------------------------------------------------------------------------\n",
    "#Experiment numbers\n",
    "ExpeNum = [1,2]\n",
    "#--------------------------------------------------------------------------------\n",
    "#Folders for measurements and experiments (this is how we separate shanks in folders for individual analyses)\n",
    "m164 = ['m1s'+str(s) for s in arange(8)+1]\n",
    "m264 = ['m2s'+str(s) for s in arange(8)+1]\n",
    "m364 = ['m3s'+str(s) for s in arange(8)+1]\n",
    "m464 = ['m4s'+str(s) for s in arange(8)+1]\n",
    "m564 = ['m5s'+str(s) for s in arange(8)+1]\n",
    "m664 = ['m6s'+str(s) for s in arange(8)+1]\n",
    "m764 = ['m7s'+str(s) for s in arange(8)+1]\n",
    "m864 = ['m8s'+str(s) for s in arange(8)+1]\n",
    "m964 = ['m9s'+str(s) for s in arange(8)+1]\n",
    "m1064 = ['m10s'+str(s) for s in arange(8)+1]\n",
    "\n",
    "M = [m164,m264,m364,m464,m564,m664,m764,m864,m964,m1064]\n",
    "\n",
    "shanks = ['_ele_01_ele08.kwik',\n",
    "          '_ele_09_ele16.kwik',\n",
    "          '_ele_17_ele24.kwik',\n",
    "          '_ele_25_ele32.kwik',\n",
    "          '_ele_33_ele40.kwik',\n",
    "          '_ele_41_ele48.kwik',\n",
    "          '_ele_49_ele56.kwik',\n",
    "          '_ele_57_ele64.kwik']\n",
    "#--------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------\n",
    "#Kwik files    \n",
    "base = {}\n",
    "files = {}\n",
    "#--------------------------------------------------------------------------------\n",
    "exp = 1\n",
    "base[exp] = ['EXPECT-151029-'+str(i) for i in arange(10)+1]\n",
    "files[exp] ={}\n",
    "for reps in arange(10):\n",
    "    files[exp][reps+1] = [ base[exp][reps]+shanks[i] for i in arange(8)]\n",
    "#--------------------------------------------------------------------------------\n",
    "exp = 2\n",
    "base[exp] = ['EXPECT-151217-'+str(i) for i in arange(10)+1]\n",
    "files[exp] ={}\n",
    "for reps in arange(7):\n",
    "    files[exp][reps+1] = [ base[exp][reps]+shanks[i] for i in arange(8)]\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Here I create my dictionary of experiments\n",
    "Expe={}\n",
    "for num in ExpeNum: \n",
    "    Expe[num] = dict()\n",
    "#---------------------------------------\n",
    "stimfiles = {}\n",
    "timefiles = {}\n",
    "eptimefiles = {}\n",
    "\n",
    "exp =1\n",
    "m=0\n",
    "for Meas in M[0:10]:\n",
    "    i=0\n",
    "    for meas in Meas:\n",
    "        Expe[exp][meas] = files[exp][m+1][i]\n",
    "        i+=1\n",
    "    m+=1\n",
    "exp=2\n",
    "m=0\n",
    "for Meas in M[0:7]:\n",
    "    i=0\n",
    "    for meas in Meas:\n",
    "        Expe[exp][meas] = files[exp][m+1][i]\n",
    "        i+=1\n",
    "    m+=1\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Stim files\n",
    "for exp in ExpeNum:\n",
    "    stimfiles[exp] = [base[exp][rep-1][:-1] + 'stims-' + str(rep) + '.txt' for rep in files[1]]\n",
    "    timefiles[exp] = [base[exp][rep-1][:-1] + 'times-' + str(rep) + '.txt' for rep in files[1]]\n",
    "    eptimefiles[exp] = [base[exp][rep-1][:-1] + 'ep_times-' + str(rep) + '.txt' for rep in files[1]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and load data files from experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "group: 2\n",
      "m7s1\n",
      "Total episodes:  15\n",
      "Total stims per episode:  28\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can't convert 'float' object to str implicitly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-293-8b8092e34a15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m                 \u001b[0mepfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrootF\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'EXP_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0meptimefiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mexpe\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_meas\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[0mStims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_dict_stim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstimfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimefile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-286-a9e246d0dc41>\u001b[0m in \u001b[0;36mbuild_dict_stim\u001b[1;34m(stimfile, timefile, epdurationfile)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mst_count\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstims_ep\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mst_count\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mstims_ep\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mstarts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mep\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mep_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0mst_count\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m#------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't convert 'float' object to str implicitly"
     ]
    }
   ],
   "source": [
    "global binname, textname\n",
    "#---------------------------------------------------------------------------------------\n",
    "SelExp = [2]                         #select experiment numbers!\n",
    "grupete = [2]   #select cluster groups! 2 for good clusters 1 for multiunits, 3 for unsorted\n",
    "\n",
    "#select measurement and/or shanks!\n",
    "Measurements = m764[0:1]           #['m1s1']#['m3s1','m3s3']#m12[-4:]#['m1s1','m1s2','m1s3','m1s4']   \n",
    "\n",
    "rootF = '/media/matias/DATA/WORKSPACE2/'    \n",
    "\n",
    "dirs =[]\n",
    "#--------------------------------------------------------------------------------\n",
    "# Loop Experiments\n",
    "#--------------------------------------------------------------------------------\n",
    "last_exp=0     #we use this to load stim only when we change experiment\n",
    "for expe in SelExp:\n",
    "    \n",
    "    PSTHdata = {}\n",
    "    PSTH_spikes_counts = {}\n",
    "    \n",
    "    #Measurements = sorted(Expe[expe])                         #uncommento to select all\n",
    "    print(expe)\n",
    "   \n",
    "    last_meas =0   #we use this to find when we change measurement to load Vtag and stim again\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    #loop goodunits, multiunits, unsorted...\n",
    "    for group in grupete:   #2 for good clusters 1 for multiunits 3 for unsorted\n",
    "        #folder names\n",
    "        if group ==3:\n",
    "            dirs  = [rootF + 'OUTPUT/EXP_'+str(expe)]\n",
    "        if group ==2:\n",
    "            dirs  = [rootF + 'OUTPUT/EXP_'+str(expe)]\n",
    "        if group ==1:\n",
    "            dirs  = [rootF + 'OUTPUT/EXP_'+str(expe)]\n",
    "        #--------------------------------------------------------------------------------\n",
    "        #create output folders\n",
    "        for dir in dirs:\n",
    "            if not os.path.exists(dir):\n",
    "                os.makedirs(dir) \n",
    "        dire = dirs[0] +'/'\n",
    "        titles = 'Exp'+ str(expe) + '_Meas_' + meas[1] + '_Shank_' + meas[3]\n",
    "        #--------------------------------------------------------------------------------\n",
    "        print('group:', group)\n",
    "        #--------------------------------------------------------------------------------\n",
    "        #loop measurements and shanks\n",
    "        #Measurements = sorted((Expe[expe]))\n",
    "        \n",
    "        for meas in Measurements:           \n",
    "            print(meas)\n",
    "            current_meas = int(meas[1])   #measurement number\n",
    "            #---------------------------------------------------------------\n",
    "            #This is to account for diffrerent stims when looping diffrerent experiments\n",
    "            if current_meas!=last_meas:\n",
    "                stimfile = rootF + 'EXP_' + str(expe) + '/' + stimfiles[expe][current_meas-1]\n",
    "                timefile = rootF + 'EXP_' + str(expe) + '/' +timefiles[expe][current_meas-1]\n",
    "                epfile = rootF + 'EXP_' + str(expe) + '/' +eptimefiles[expe][current_meas-1]\n",
    "                \n",
    "                Stims = build_dict_stim(stimfile, timefile, epfile)\n",
    "          \n",
    "            \n",
    "            #select datafile\n",
    "            sp_file = rootF + 'EXP_' + str(expe) +'/Spike_Sort/'+ meas +'/'+ Expe[expe][meas]\n",
    "            #load datafile\n",
    "            Spikes, sampling_freq = readkwikinfo(sp_file, group)  \n",
    "                    \n",
    "            if len(Spikes.keys())>0:                              #do only if there are clusters\n",
    "                #Build PSTHs\n",
    "                print('   building psths')\n",
    "    \n",
    "                #PSTH_data = BuildPSTH(Stims, Spikes, sampling_freq, exp, meas) :\n",
    "               \n",
    "    print('   saving')\n",
    "    if group == 2:\n",
    "        filesave =rootF +'Expect_git/data/'+'psthdata' + str(expe)\n",
    "    else:\n",
    "        filesave =rootF +'S2_git/data/'+ 'psthdataMultiR' + str(expe)\n",
    "        \n",
    "    #save_obj(PSTHdata,filesave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-286-a9e246d0dc41>\u001b[0m(47)\u001b[0;36mbuild_dict_stim\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     46 \u001b[1;33m            \u001b[0mep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mst_count\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mstims_ep\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 47 \u001b[1;33m            \u001b[0mstarts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mep\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mep_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     48 \u001b[1;33m            \u001b[0mst_count\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> ep\n",
      "0\n",
      "ipdb> st\n",
      "0\n",
      "ipdb> t\n",
      "'       0.067'\n",
      "ipdb> ep\n",
      "0\n",
      "ipdb> ep_length\n",
      "78099.83333333333\n",
      "ipdb> ep*ep_length\n",
      "0.0\n",
      "ipdb> ep*ep_length+t\n",
      "*** TypeError: unsupported operand type(s) for +: 'float' and 'str'\n",
      "ipdb> ep.type()\n",
      "*** AttributeError: 'int' object has no attribute 'type'\n",
      "ipdb> type(ep)\n",
      "<class 'int'>\n",
      "ipdb> type(t)\n",
      "<class 'str'>\n",
      "ipdb> times\n",
      "['       0.067', '    1001.633', '    2001.600', '    3001.533', '    5501.367', '    8001.233', '   10501.067', '   13000.933', '   15500.767', '   20500.600', '   25500.400', '   28000.233', '   29000.167', '   33999.967', '   34999.933', '   35999.867', '   38499.700', '   39499.667', '   44499.467', '   45499.400', '   47999.233', '   52999.033', '   57998.867', '   62998.667', '   67998.467', '   68998.400', '   69998.333', '   74998.133', '', '       0.067', '    1001.633', '    6001.433', '    8501.300', '   13501.100', '   18500.900', '   23500.700', '   26000.567', '   27000.500', '   32000.300', '   34500.167', '   37000.000', '   39499.867', '   40499.800', '   42999.633', '   47999.433', '   48999.400', '   53999.200', '   54999.133', '   57498.967', '   58498.933', '   60998.767', '   61998.700', '   66998.500', '   67998.467', '   68998.400', '   69998.333', '   74998.133', '', '       0.067', '    1001.667', '    3501.500', '    6001.367', '    8501.200', '   11001.067', '   12001.000', '   17000.800', '   18000.733', '   23000.533', '   25500.400', '   26500.333', '   29000.200', '   34000.000', '   36499.833', '   37499.767', '   39999.633', '   44999.433', '   49999.233', '   50999.167', '   51999.133', '   54498.967', '   55498.900', '   60498.700', '   61498.667', '   66498.467', '   67498.400', '   72498.200', '', '       0.067', '    1001.667', '    3501.500', '    4501.467', '    5501.400', '    8001.233', '   13001.033', '   15500.900', '   18000.767', '   23000.567', '   24000.500', '   26500.333', '   29000.200', '   31500.033', '   36499.867', '   41499.667', '   46499.467', '   51499.267', '   52499.200', '   57499.000', '   62498.800', '   64998.667', '   65998.600', '   66998.533', '   69498.400', '   70498.333', '   71498.267', '   72498.200', '', '       0.067', '    1001.633', '    2001.600', '    7001.400', '   12001.200', '   17001.000', '   18000.933', '   20500.800', '   23000.633', '   25500.500', '   28000.333', '   33000.133', '   34000.067', '   38999.867', '   39999.833', '   42499.667', '   44999.533', '   45999.467', '   46999.400', '   49499.267', '   51999.100', '   56998.900', '   61998.700', '   62998.667', '   65498.500', '   70498.300', '   75498.100', '   76498.033', '', '       0.067', '    1001.667', '    3501.500', '    4501.433', '    5501.400', '   10501.200', '   13001.033', '   18000.833', '   20500.700', '   21500.633', '   26500.433', '   31500.233', '   32500.167', '   35000.033', '   37499.867', '   39999.733', '   42499.600', '   47499.400', '   48499.333', '   49499.267', '   50499.200', '   52999.067', '   57998.867', '   62998.667', '   67998.467', '   68998.400', '   71498.267', '   72498.200', '', '       0.067', '    2501.567', '    3501.533', '    6001.367', '    8501.233', '   13501.033', '   18500.833', '   19500.767', '   20500.700', '   23000.567', '   25500.400', '   30500.200', '   33000.067', '   34000.000', '   34999.933', '   37499.800', '   42499.600', '   43499.533', '   48499.333', '   49499.267', '   54499.067', '   55499.033', '   60498.833', '   65498.633', '   66498.567', '   67498.500', '   69998.367', '   72498.200', '', '       0.067', '    2501.533', '    3501.500', '    8501.300', '   13501.100', '   14501.033', '   17000.900', '   19500.733', '   24500.533', '   25500.467', '   26500.433', '   29000.267', '   30000.200', '   32500.067', '   37499.867', '   42499.667', '   47499.467', '   49999.333', '   50999.267', '   51999.200', '   52999.133', '   55499.000', '   60498.800', '   65498.600', '   67998.433', '   70498.300', '   71498.233', '   76498.033', '', '       0.067', '    1001.633', '    2001.567', '    4501.433', '    5501.367', '    8001.233', '   10501.067', '   11501.000', '   16500.800', '   21500.633', '   26500.433', '   31500.233', '   32500.167', '   33500.100', '   35999.967', '   40999.767', '   41999.700', '   44499.533', '   49499.367', '   51999.200', '   52999.133', '   55499.000', '   60498.800', '   65498.600', '   67998.433', '   72998.267', '   73998.200', '   74998.133', '', '       0.067', '    1001.667', '    3501.500', '    4501.433', '    7001.300', '   12001.100', '   13001.033', '   18000.833', '   20500.700', '   25500.500', '   30500.300', '   31500.233', '   34000.100', '   35000.033', '   35999.967', '   36999.900', '   39499.767', '   40499.700', '   45499.500', '   50499.300', '   55499.100', '   56499.067', '   61498.867', '   63998.700', '   66498.567', '   68998.400', '   71498.267', '   76498.067', '', '       0.067', '    2501.533', '    5001.400', '    6001.333', '    7001.267', '    8001.233', '   13001.033', '   15500.867', '   16500.800', '   17500.767', '   22500.567', '   25000.400', '   27500.267', '   30000.100', '   32499.967', '   34999.800', '   39999.600', '   40999.567', '   45999.367', '   50999.167', '   55998.967', '   58498.800', '   59498.767', '   64498.567', '   65498.500', '   66498.433', '   67498.367', '   72498.167', '', '       0.067', '    1001.700', '    2001.633', '    4501.500', '    9501.300', '   14501.100', '   15501.033', '   16500.967', '   17500.900', '   18500.867', '   23500.667', '   28500.467', '   31000.300', '   33500.167', '   34500.100', '   39499.900', '   41999.767', '   44499.600', '   46999.467', '   47999.400', '   52999.200', '   53999.133', '   58998.933', '   61498.800', '   63998.633', '   64998.600', '   67498.433', '   72498.233', '', '       0.067', '    1001.633', '    6001.433', '    8501.300', '    9501.233', '   12001.100', '   13001.033', '   18000.833', '   23000.633', '   24000.567', '   29000.367', '   31500.233', '   32500.167', '   35000.033', '   35999.967', '   40999.767', '   43499.600', '   44499.567', '   45499.500', '   46499.433', '   47499.367', '   49999.233', '   54999.033', '   59998.833', '   64998.633', '   69998.433', '   72498.300', '   74998.133', '', '       0.067', '    1001.633', '    3501.500', '    6001.333', '    8501.200', '   13501.000', '   14500.933', '   15500.867', '   16500.833', '   19000.667', '   24000.467', '   26500.333', '   27500.267', '   28500.200', '   33500.000', '   38499.800', '   39499.767', '   44499.567', '   49499.367', '   54499.167', '   55499.100', '   57998.967', '   62998.767', '   65498.600', '   67998.467', '   68998.400', '   69998.333', '   74998.133', '', '       0.067', '    2501.567', '    3501.500', '    4501.433', '    9501.233', '   12001.100', '   14500.933', '   19500.733', '   22000.600', '   27000.400', '   29500.233', '   32000.100', '   33000.033', '   33999.967', '   36499.833', '   37499.767', '   39999.633', '   44999.433', '   49999.233', '   54999.033', '   55998.967', '   60998.767', '   65998.567', '   66998.500', '   67998.467', '   68998.400', '   69998.333', '   72498.200', '']\n",
      "ipdb> type(times)\n",
      "<class 'list'>\n",
      "ipdb> times[0]\n",
      "'       0.067'\n",
      "ipdb> type(times[0])\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "%debug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['psth_counts', 'meas', 'psth_length', 'clusnum', 'psth_times', 'exp', 'shank'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filesave\n",
    "\n",
    "sorted(list(PSTHdata.keys()))\n",
    "PSTHdata['exp20_m1s1_c29'].keys()\n",
    "\n",
    "data = rootF +'S2_git/data/'+'psthdata' + str(22)\n",
    "\n",
    "a = load_obj(data)\n",
    "\n",
    "a['exp22_m3s4_c1138'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#update spiketimes to wavedataAll\n",
    "SelExp = [20] #[22,24,26,27,28,29,30,31,32] #Expe                                        #select experiment numbers!\n",
    "\n",
    "Folder = '/home/matias/WORKSPACE/S2_git/data'    \n",
    "\n",
    "for e in SelExp:\n",
    "\n",
    "    data = Folder +'/wavedata'+ str(e)\n",
    "    wavedata = load_obj(data)\n",
    "\n",
    "    idx = list(wavedata.keys())\n",
    "\n",
    "    datapsth = Folder +'/psthdata' + str(e)\n",
    "    psthdata = load_obj(datapsth)\n",
    "\n",
    "\n",
    "    for n in idx:\n",
    "        wavedata[n].update(psthdata[n])    \n",
    "            \n",
    "    data = Folder +'data/datamix' + str(e)\n",
    "\n",
    "    save_obj(wavedata, data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = list(PSTHdata.keys())\n",
    "PSTHdata[idx[0]].keys()\n",
    "#PSTHdata[idx[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Spikes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PSTHdata[idx[0]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
