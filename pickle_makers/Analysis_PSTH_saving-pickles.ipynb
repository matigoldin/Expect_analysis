{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    " %pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from scipy import *\n",
    "from scipy import stats, io\n",
    "import numpy as np\n",
    "import struct\n",
    "import tables as tb\n",
    "from attrdict import AttrDict\n",
    "import matplotlib.pyplot as plt\n",
    "import os as os\n",
    "from phy.io import KwikModel\n",
    "import codecs as codecs\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "#SAVING BINARY OBJECTS DATA\n",
    "#need to automate data folder creation\n",
    "#----------------------------------------------------------------------------------------\n",
    "import pickle \n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open( name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open( name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS TO BUILD PSTHs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------\n",
    "# GET STIMTIMES\n",
    "#---------------------------------------------------------\n",
    "def get_stimtimes(stimfile,timefile):\n",
    "    \n",
    "    stims = open(stimfile, 'r')\n",
    "    times = open(timefile, 'r')\n",
    "    \n",
    "    stimdata = stims.read().splitlines()\n",
    "    timedata = times.read().splitlines()\n",
    "   \n",
    "    stims.close()\n",
    "    times.close()\n",
    "    \n",
    "    return stimdata, timedata\n",
    "\n",
    "#---------------------------------------------------------\n",
    "# BUILD DICT STIM, reads stims and times of .txt files of experiments\n",
    "#---------------------------------------------------------\n",
    "def build_dict_stim(stimfile, timefile):\n",
    "\n",
    "    stims, times = get_stimtimes(stimfile,timefile)\n",
    "    #------------------------------------------\n",
    "    # count number of episodes\n",
    "    episodes=1\n",
    "    stims_ep=0\n",
    "    for time in times[:-1]:             #last line is blank, we skip it\n",
    "        if time == '': \n",
    "            episodes+=1\n",
    "        if episodes ==1:\n",
    "            stims_ep+=1\n",
    "    print('Total episodes: ', episodes)        \n",
    "    print('Total stims per episode: ', stims_ep)        \n",
    "    #------------------------------------------\n",
    "    # starting times of each stimulus\n",
    "    starts = np.zeros([episodes, stims_ep])\n",
    "    tot_stims = episodes*stims_ep\n",
    "\n",
    "    st_count=0\n",
    "    for t in times[:-1]:\n",
    "        if t!='':\n",
    "            st = st_count % stims_ep\n",
    "            ep = st_count // stims_ep \n",
    "            starts[ep,st] = t\n",
    "            st_count+=1\n",
    "    #------------------------------------------\n",
    "    # stims        \n",
    "    st_pad = zeros([episodes,stims_ep]) # 1 row, 2 arc, 3 pad\n",
    "    st_type = zeros([episodes,stims_ep]) # 1 hold, 2 pass, 3 release        \n",
    "    st_isi = zeros([episodes,stims_ep]) # 10 , 20, 50\n",
    "    st_rep = zeros([episodes,stims_ep]) # 2, 5, 10\n",
    "    st_ctrl = zeros([episodes,stims_ep]) # 0, blank, 1 ctrl1, 2 ctrl2, 3 ctrl3, 10 normal \n",
    "    # dictionary of stims\n",
    "    st_logic = {} \n",
    "    st_logic['pad'] = {'ROW' : 1, 'ARC' : 2, 'PAD' : 3}\n",
    "    st_logic['types'] = {'hold' : 1, 'pass' : 2, 'release' : 3}\n",
    "    st_logic['ctrl'] = {'BLANK' : 0, 'Ctrl1' : 1, 'Ctrl2' : 2, 'Ctrl3' : 3, 'Normal' : 10}\n",
    "\n",
    "    ep=0\n",
    "    st=0\n",
    "    # get stims\n",
    "    for stim in stims[:-3]:           #last three lines useless\n",
    "        line = stim.split()\n",
    "        if line and ep<episodes:\n",
    "\n",
    "            if line[1]=='BLANK':\n",
    "                st+=1\n",
    "                if st%stims_ep==0:\n",
    "                    st=0\n",
    "                    ep+=1\n",
    "            elif len(line)>3:\n",
    "                if line[1][1:4]=='ROW': st_pad[ep,st]=1\n",
    "                elif line[1][1:4]=='ARC': st_pad[ep,st]=2\n",
    "                elif line[1][1:4]=='PAD': st_pad[ep,st]=3\n",
    "\n",
    "                if line[1][5:-1]=='Hold': st_type[ep,st]=1\n",
    "                elif line[1][5:-1]=='Pass': st_type[ep,st]=2\n",
    "                elif line[1][5:-1]=='Release': st_type[ep,st]=3\n",
    "\n",
    "                if line[3]=='REP_2': st_rep[ep,st]=2\n",
    "                elif line[3]=='REP_5': st_rep[ep,st]=5\n",
    "                elif line[3]=='REP_10': st_rep[ep,st]=10\n",
    "\n",
    "                if line[5]=='ISI_10': st_isi[ep,st]=10\n",
    "                elif line[5]=='ISI_20': st_isi[ep,st]=20\n",
    "                elif line[5]=='ISI_50': st_isi[ep,st]=50\n",
    "                    \n",
    "                if line[7]=='Normal': st_ctrl[ep,st]=10\n",
    "                elif line[7][0:5]=='Ctrl1': st_ctrl[ep,st]=1\n",
    "                elif line[7][0:5]=='Ctrl2': st_ctrl[ep,st]=2\n",
    "                elif line[7][0:5]=='Ctrl3': st_ctrl[ep,st]=3\n",
    "                elif line[7][0:5]=='Ctrl4': st_ctrl[ep,st]=4\n",
    "\n",
    "                st+=1\n",
    "                if st%stims_ep==0:\n",
    "                    st=0\n",
    "                    ep+=1\n",
    "\n",
    "    Stim_dict = AttrDict({'st_logic':st_logic, 'episodes': episodes  ,'stims_ep':stims_ep  ,'st_times': starts})\n",
    "    Stim_dict.update({'st_isi':st_isi,'st_rep':st_rep,'st_type':st_type,'st_ctrl': st_ctrl,'st_pad':st_pad})\n",
    "    \n",
    "    return Stim_dict\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# BUILD HIST DICTIONARY\n",
    "#----------------------------------------------------------------------------------------\n",
    "import copy as cp\n",
    "\n",
    "def build_hist_dict():\n",
    "    isis = [10,20,50]\n",
    "    reps = [2,5,10]\n",
    "    pads = ['arc','row','pad']\n",
    "    types = ['hold','pas','release']\n",
    "    \n",
    "    Isis ={}\n",
    "    for i in isis:\n",
    "        Isis[i]= []\n",
    "    \n",
    "    Reps ={}\n",
    "    for r in reps:\n",
    "        Reps[r] = cp.deepcopy(Isis)\n",
    "    \n",
    "    Pads = {}\n",
    "    for p in pads:\n",
    "        Pads[p] = cp.deepcopy(Reps)\n",
    "    \n",
    "    Types = {}\n",
    "    for t in types:\n",
    "        Types[t] = cp.deepcopy(Pads)\n",
    "    \n",
    "    Normal = cp.deepcopy(Types)\n",
    "    Ctrl1 = cp.deepcopy(Types)\n",
    "    Ctrl2 = cp.deepcopy(Types)\n",
    "    Ctrl3 = cp.deepcopy(Types)\n",
    "    Ctrl4 = cp.deepcopy(Types)\n",
    "    \n",
    "    counts_n = cp.deepcopy(Normal)\n",
    "    counts_c1 = cp.deepcopy(Normal)\n",
    "    counts_c2 = cp.deepcopy(Normal)\n",
    "    counts_c3 = cp.deepcopy(Normal)\n",
    "    counts_c4 = cp.deepcopy(Normal)\n",
    "    \n",
    "    Counts ={}\n",
    "    Counts['Normal'] = counts_n\n",
    "    Counts['Ctrl1'] = counts_c1\n",
    "    Counts['Ctrl2'] = counts_c2\n",
    "    Counts['Ctrl3'] = counts_c3\n",
    "    Counts['Ctrl4'] = counts_c4\n",
    "    Counts['Blank'] = []\n",
    "    \n",
    "    hist_logic = 'Type x Pad x Rep x Isi'\n",
    "    hist = AttrDict({ 'Blank' :[],  'Normal': Normal, 'Ctrl1':Ctrl1 , 'Ctrl2':Ctrl2 , 'Ctrl3': Ctrl3, 'Ctrl4': Ctrl4 , 'hist_logic': hist_logic, 'Counts':Counts})\n",
    "\n",
    "    return hist\n",
    "    \n",
    "#----------------------------------------------------------------------------------------\n",
    "# READKWIKINFO\n",
    "#----------------------------------------------------------------------------------------\n",
    "# We read the data of the output from klusterkwik: spike times and cluster-number of each\n",
    "# cluster-number is in klustaviewa series (can be as high as 130 e.g.)\n",
    "# Grupete stands for cluster groups! 2: good clusters, 1: multiunits, 0: unsorted, 3: noise\n",
    "def readkwikinfo(kwik, grupete=2):\n",
    "    model = KwikModel(kwik) # load kwik model from file\n",
    "    spiketimes = model.spike_times # extract the absolute spike times\n",
    "    clusters = model.cluster_groups # extract the cluster names\n",
    "    sample_rate = model.sample_rate # extract sampling freq\n",
    "    \n",
    "    spikedata = {} # initialise dictionary\n",
    "    for cluster in clusters.keys():\n",
    "        clustergroup = clusters[cluster]\n",
    "        if clustergroup==grupete: # only look at specified type of cluster, 0 = noise, 1 = MUA, 2 = GOOD, 3 = unsorted\n",
    "            spiketimematrix = AttrDict({'spike_times': np.zeros(len(spiketimes[where(model.spike_clusters==cluster)]))})\n",
    "            spiketimematrix.spike_times = spiketimes[where(model.spike_clusters==cluster)]\n",
    "            spikedata[cluster] = spiketimematrix # data structure is a dictionary with attribute accessible spiketimes\n",
    "            # attribute accessible means that spikedata.spike_times works, normal dictionaries would be spikedata[spike_times]\n",
    "    \n",
    "    model.close()\n",
    "    \n",
    "    return spikedata, sample_rate\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# BUILDS PSTH\n",
    "#----------------------------------------------------------------------------------------\n",
    "def BuildPSTH(Stims, Spikes, sampling_freq, exp, meas):\n",
    "    \n",
    "    stimtimes = {}\n",
    "    stim_samp = 1/.0009997575757\n",
    "    # make an 'output dict'\n",
    "    # the PSTH will be built on -tbefore:tafter\n",
    "    PSTH_times = {}\n",
    "    \n",
    "    # Loop each neuron and get the spikes.\n",
    "    for neuron in list(Spikes.keys()): \n",
    "        codename = 'exp'+ str(exp) + '_' + str(meas) + '_c' + str(neuron)\n",
    "        psth = AttrDict({'clusnum': neuron,'exp' : int(exp) , 'meas': int(meas[1]) , 'shank': int(meas[3])})\n",
    "        psth.update(AttrDict({'psth_counts': [] , 'psth_times': []}))\n",
    "        \n",
    "        hist= build_hist_dict()\n",
    "        \n",
    "        #loop episodes and stims_per_episode, and populate the histograms\n",
    "        for ep in arange(Stim.episodes):\n",
    "            for se in arange(Stim.stims_ep):\n",
    "                c = Stims.st_ctrl[ep][se]\n",
    "                t = Stims.st_type[ep][se]\n",
    "                p = Stims.st_pad[ep][se]\n",
    "                r = Stims.st_rep[ep][se]\n",
    "                i = Stims.st_isi[ep][se]\n",
    "                start = Stims.st_times[ep][se]\n",
    "                if c=='Blank':\n",
    "                    t_after=0.5\n",
    "                    hist[c].append (Spikes[(start <= spikes) * (spikes <= times + t_after)])\n",
    "                    hist['Counts'][c] += len(Spikes[(start <= spikes) * (spikes <= times + t_after)])\n",
    "                else:\n",
    "                    t_after = 0.5*r\n",
    "                    hist[c][t][p][r][i].append(Spikes[(start <= spikes) * (spikes <= times + t_after)])\n",
    "                    hist['Counts'][c][t][p][r][i] += lenSpikes([(start <= spikes) * (spikes <= times + t_after)])\n",
    "                                                       \n",
    "        PSTH_times[codename] = hist\n",
    "       \n",
    "    return PSTH_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total episodes:  15\n",
      "Total stims per episode:  28\n",
      "dict_keys(['st_isi', 'episodes', 'st_rep', 'st_times', 'st_ctrl', 'st_type', 'stims_ep', 'st_pad', 'st_logic'])\n",
      "dict_keys(['Blank', 'Ctrl1', 'hist_logic', 'Ctrl2', 'Normal', 'Ctrl3', 'Ctrl4', 'Counts'])\n",
      "Type x Pad x Rep x Isi\n",
      "AttrDict({'types': {'pass': 2, 'hold': 1, 'release': 3}, 'pad': {'PAD': 3, 'ROW': 1, 'ARC': 2}, 'ctrl': {'Normal': 10, 'BLANK': 0, 'Ctrl2': 2, 'Ctrl1': 1, 'Ctrl3': 3}})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 28)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Folder = '/media/matias/DATA/WORKSPACE2/EXP_2'        \n",
    "stimfile = Folder +'/EXPECT-151217-stims-7.txt'   \n",
    "timefile = Folder +'/EXPECT-151217-times-7.txt'   \n",
    "\n",
    "Stims = build_dict_stim(stimfile, timefile)\n",
    "\n",
    "print(Stims.keys())\n",
    "\n",
    "h = build_hist_dict()\n",
    "\n",
    "print(h.keys())\n",
    "print(h.hist_logic)\n",
    "\n",
    "print(Stims.st_logic)\n",
    "\n",
    "Stims.st_rep.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m10s1', 'm10s2', 'm10s3', 'm10s4', 'm10s5', 'm10s6', 'm10s7', 'm10s8']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for m in arange(10)+1:\n",
    "    M[i] = ['m'+str(m)+'s'+str(s) for s in arange(8)+1]\n",
    "\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Files and Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this cell you put all the information to make the code portable from computer to computer\n",
    "# You have to place all the file names and experiments, then you loop whichever you want to analyse\n",
    "#--------------------------------------------------------------------------------\n",
    "#Experiment numbers\n",
    "ExpeNum = [1,2]\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Folders for measurements and experiments (this is how we separate shanks in folders for individual analyses)\n",
    "\n",
    "M = 'm\n",
    "\n",
    "m164 = ['m1s'+s for s in arange(8)+1]\n",
    "m264 = ['m2s1','m2s2','m2s3','m2s4','m2s5','m2s6','m2s7','m2s8']\n",
    "m364 = ['m3s1','m3s2','m3s3','m3s4','m3s5','m3s6','m3s7','m3s8']\n",
    "m464 = ['m4s1','m4s2','m4s3','m4s4','m4s5','m4s6','m4s7','m4s8']\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Kwik files    \n",
    "\n",
    "files20 = [ 'MEAS-150707-1_ele01_ele08.kwik',\n",
    "            'MEAS-150707-1_ele09_ele16.kwik',\n",
    "            'MEAS-150707-1_ele17_ele24.kwik',\n",
    "            'MEAS-150707-1_ele25_ele32.kwik',\n",
    "            'MEAS-150707-23_ele01_ele08.kwik',\n",
    "            'MEAS-150707-23_ele16_ele09.kwik']#,\n",
    "            #'MEAS-150707-23_ele17_ele24.kwik',  not in S2\n",
    "            #'MEAS-150707-23_ele25_ele32.kwik',] not in S2\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------\n",
    "# Here I create my dictionary of experiments\n",
    "Expe={}\n",
    "Vtags={}\n",
    "Stim={}\n",
    "for num in ExpeNum: \n",
    "    Expe[num] = dict()\n",
    "    Vtags[num] = dict()\n",
    "#---------------------------------------\n",
    "i=0        \n",
    "for meas in np.append(m164[0:4],m364[0:2]):\n",
    "    Expe[20][meas] = files20[i]\n",
    "    i+=1\n",
    "#---------------------------------------\n",
    "\n",
    "    i+=1\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Vtag files \n",
    "Vtags[20] = ['MEAS-150707-1_Vtag1.dat','nada','MEAS-150707-23_Vtag1.dat']\n",
    "\n",
    "   \n",
    "#--------------------------------------------------------------------------------\n",
    "#Root folder to work in, such all will be in subfolders \n",
    "#e.g.: \"/EXP_23/m1s1/\" for data or \"/STIM/\" for stims\n",
    "rootF = '/home/matias/WORKSPACE/'    \n",
    "stimFolder = rootF +'STIM/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and load data files from experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "group: 2\n",
      "m1s1\n",
      "   reading stim at: m1s1\n",
      "   trimming stim at: m1s1\n",
      "m1s2\n",
      "   building psths\n",
      "m1s3\n",
      "   building psths\n",
      "m1s4\n",
      "   building psths\n",
      "m3s1\n",
      "   reading stim at: m3s1\n",
      "   trimming stim at: m3s1\n",
      "   building psths\n",
      "m3s2\n",
      "   building psths\n",
      "m3s3\n",
      "   building psths\n",
      "m3s4\n",
      "   building psths\n",
      "   saving\n"
     ]
    }
   ],
   "source": [
    "global binname, textname\n",
    "#---------------------------------------------------------------------------------------\n",
    "SelExp = [1]                         #select experiment numbers!\n",
    "grupete = [2]   #select cluster groups! 2 for good clusters 1 for multiunits, 3 for unsorted\n",
    "\n",
    "#select measurement and/or shanks!\n",
    "#Measurements = m264[7:8]           #['m1s1']#['m3s1','m3s3']#m12[-4:]#['m1s1','m1s2','m1s3','m1s4']   \n",
    "\n",
    "#select type of stimuli, for PSTH is only 'F' and this does not change anything\n",
    "#choices = ['F','C','U']                      #select stimulus type (for STA and STC)\n",
    "\n",
    "dirs =[]\n",
    "#--------------------------------------------------------------------------------\n",
    "# Loop Experiments\n",
    "#--------------------------------------------------------------------------------\n",
    "last_exp=0     #we use this to load stim only when we change experiment\n",
    "for expe in SelExp:\n",
    "    \n",
    "    PSTHdata = {}\n",
    "    PSTH_spikes_counts = {}\n",
    "    \n",
    "    Measurements = sorted(Expe[expe])                         #uncommento to select all\n",
    "    print(expe)\n",
    "\n",
    "    #This two lines are to account for diffrerent stims when looping diffrerent experiments\n",
    "    stimfile = stimFolder + Stim[expe] \n",
    "    timefile = stimFolder + Times[expe] \n",
    "        \n",
    "    Stims = build_dict_stim(stimfile, timefile)\n",
    "    \n",
    "    last_meas =0   #we use this to find when we change measurement to load Vtag and stim again\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    #loop goodunits, multiunits, unsorted...\n",
    "    for group in grupete:   #2 for good clusters 1 for multiunits 3 for unsorted\n",
    "        #folder names\n",
    "        if group ==3:\n",
    "            dirs  = [rootF + 'OUTPUT/EXP_'+str(expe)]\n",
    "        if group ==2:\n",
    "            dirs  = [rootF + 'OUTPUT/EXP_'+str(expe)]\n",
    "        if group ==1:\n",
    "            dirs  = [rootF + 'OUTPUT/EXP_'+str(expe)]\n",
    "        #--------------------------------------------------------------------------------\n",
    "        #create output folders\n",
    "        for dir in dirs:\n",
    "            if not os.path.exists(dir):\n",
    "                os.makedirs(dir) \n",
    "        dire = dirs[0] +'/'\n",
    "        titles = 'Exp'+ str(expe) + '_Meas_' + meas[1] + '_Shank_' + meas[3]\n",
    "        #--------------------------------------------------------------------------------\n",
    "        print('group:', group)\n",
    "        #--------------------------------------------------------------------------------\n",
    "        #loop measurements and shanks\n",
    "        #Measurements = sorted((Expe[expe]))\n",
    "        \n",
    "        for meas in Measurements:           \n",
    "            print(meas)\n",
    "            current_meas = int(meas[1])   #measurement number\n",
    "            #---------------------------------------------------------------\n",
    "            #select datafile\n",
    "            sp_file = rootF_kwiks + 'EXP_' + str(expe) +'/Spike_Sort/'+ meas +'/'+ Expe[expe][meas]\n",
    "            #load datafile\n",
    "            Spikes, sampling_freq = readkwikinfo(sp_file, group)  \n",
    "                    \n",
    "            if len(Spikes.keys())>0:                              #do only if there are clusters\n",
    "                #Build PSTHs\n",
    "                print('   building psths')\n",
    "    \n",
    "                PSTH_data = BuildPSTH(Stims, Spikes, sampling_freq, exp, meas) :\n",
    "               \n",
    "    print('   saving')\n",
    "    if group == 2:\n",
    "        filesave =rootF +'Expect_git/data/'+'psthdata' + str(expe)\n",
    "    else:\n",
    "        filesave =rootF +'S2_git/data/'+ 'psthdataMultiR' + str(expe)\n",
    "        \n",
    "    save_obj(PSTHdata,filesave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['psth_counts', 'meas', 'psth_length', 'clusnum', 'psth_times', 'exp', 'shank'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filesave\n",
    "\n",
    "sorted(list(PSTHdata.keys()))\n",
    "PSTHdata['exp20_m1s1_c29'].keys()\n",
    "\n",
    "data = rootF +'S2_git/data/'+'psthdata' + str(22)\n",
    "\n",
    "a = load_obj(data)\n",
    "\n",
    "a['exp22_m3s4_c1138'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#update spiketimes to wavedataAll\n",
    "SelExp = [20] #[22,24,26,27,28,29,30,31,32] #Expe                                        #select experiment numbers!\n",
    "\n",
    "Folder = '/home/matias/WORKSPACE/S2_git/data'    \n",
    "\n",
    "for e in SelExp:\n",
    "\n",
    "    data = Folder +'/wavedata'+ str(e)\n",
    "    wavedata = load_obj(data)\n",
    "\n",
    "    idx = list(wavedata.keys())\n",
    "\n",
    "    datapsth = Folder +'/psthdata' + str(e)\n",
    "    psthdata = load_obj(datapsth)\n",
    "\n",
    "\n",
    "    for n in idx:\n",
    "        wavedata[n].update(psthdata[n])    \n",
    "            \n",
    "    data = Folder +'data/datamix' + str(e)\n",
    "\n",
    "    save_obj(wavedata, data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = list(PSTHdata.keys())\n",
    "PSTHdata[idx[0]].keys()\n",
    "#PSTHdata[idx[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Spikes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PSTHdata[idx[0]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
