{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['fft', 'log10', 'power', 'sqrt', 'arccos', 'linalg', 'arctanh', 'show_config', 'copy', '__version__', 'arcsin', 'log2', 'log', 'test']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    " %pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from scipy import *\n",
    "from scipy import stats, io\n",
    "import numpy as np\n",
    "import struct\n",
    "import tables as tb\n",
    "from attrdict import AttrDict\n",
    "import matplotlib.pyplot as plt\n",
    "import os as os\n",
    "from phy.io import KwikModel\n",
    "import codecs as codecs\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "#SAVING BINARY OBJECTS DATA\n",
    "#need to automate data folder creation\n",
    "#----------------------------------------------------------------------------------------\n",
    "import pickle \n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open( name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open( name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS TO BUILD PSTHs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------\n",
    "# GET EPDURATION\n",
    "#---------------------------------------------------------\n",
    "def get_ep_duration(eptimefile):\n",
    "    \n",
    "    eptimesf = open(eptimefile, 'r')\n",
    "    eptimes = [float(x)/30 for x in eptimesf.read().split()]\n",
    "    eptimesf.close()\n",
    "   \n",
    "    return eptimes\n",
    "\n",
    "#---------------------------------------------------------\n",
    "# GET STIMTIMES\n",
    "#---------------------------------------------------------\n",
    "def get_stimtimes(stimfile,timefile):\n",
    "    \n",
    "    stims = open(stimfile, 'r')\n",
    "    times = open(timefile, 'r')\n",
    "    \n",
    "    stimdata = stims.read().splitlines()\n",
    "    timedata = times.read().splitlines()\n",
    " \n",
    "    stims.close()\n",
    "    times.close()\n",
    "    \n",
    "    return stimdata, timedata\n",
    "#---------------------------------------------------------\n",
    "# BUILD DICT STIM, reads stims and times of .txt files of experiments\n",
    "#---------------------------------------------------------\n",
    "def build_dict_stim(stimfile, timefile, epdurationfile):\n",
    "\n",
    "    stims, times = get_stimtimes(stimfile,timefile)\n",
    "    #------------------------------------------\n",
    "    # count number of episodes\n",
    "    episodes=1\n",
    "    stims_ep=0\n",
    "    for time in times[:-1]:             #last line is blank, we skip it\n",
    "        if time == '': \n",
    "            episodes+=1\n",
    "        if episodes ==1:\n",
    "            stims_ep+=1\n",
    "    print('Total episodes: ', episodes)        \n",
    "    print('Total stims per episode: ', stims_ep)        \n",
    "    #------------------------------------------\n",
    "    # get episode duration\n",
    "    ep_duration = get_ep_duration(epdurationfile)\n",
    "    ####\n",
    "    # for the formatting I have now:           #####################X   XXXXXXXXXXXXXXXXXX\n",
    "    ep_length = ep_duration[6]\n",
    "    \n",
    "    ###\n",
    "    #------------------------------------------\n",
    "    # starting times of each stimulus\n",
    "    starts = np.zeros([episodes, stims_ep])\n",
    "    tot_stims = episodes*stims_ep\n",
    "\n",
    "    st_count=0\n",
    "    for t in times[:-1]:\n",
    "        if t!='':\n",
    "            st = st_count % stims_ep\n",
    "            ep = st_count // stims_ep \n",
    "            starts[ep,st] = float(t) + ep*ep_length\n",
    "            st_count+=1\n",
    "    #------------------------------------------\n",
    "    # stims        \n",
    "    st_pad = zeros([episodes,stims_ep]) # 1 row, 2 arc, 3 pad\n",
    "    st_types = zeros([episodes,stims_ep]) # 1 hold, 2 pass, 3 release        \n",
    "    st_isi = zeros([episodes,stims_ep]) # 10 , 20, 50\n",
    "    st_rep = zeros([episodes,stims_ep]) # 2, 5, 10\n",
    "    st_ctrl = zeros([episodes,stims_ep]) # 0, blank, 1 ctrl1, 2 ctrl2, 3 ctrl3, 10 normal \n",
    "    # dictionary of stims\n",
    "    st_logic = {} \n",
    "    st_logic['pad'] = {'1' : 'ROW' , '2' : 'ARC'  , '3': 'PAD' }\n",
    "    st_logic['types'] = { '1':'hold', '2': 'pass'  , '3': 'release'}\n",
    "    st_logic['ctrl'] = {'0' : 'BLANK', '1' : 'Ctrl1', '2' : 'Ctrl2', '3' : 'Ctrl3', '10' : 'Normal'}\n",
    "\n",
    "    ep=0\n",
    "    st=0\n",
    "    # get stims\n",
    "    for stim in stims[:-3]:           #last three lines useless\n",
    "        line = stim.split()\n",
    "        if line and ep<episodes:\n",
    "\n",
    "            if line[1]=='BLANK':\n",
    "                st+=1\n",
    "                if st%stims_ep==0:\n",
    "                    st=0\n",
    "                    ep+=1\n",
    "            elif len(line)>3:\n",
    "                if line[1][1:4]=='ROW': st_pad[ep,st]=1\n",
    "                elif line[1][1:4]=='ARC': st_pad[ep,st]=2\n",
    "                elif line[1][1:4]=='PAD': st_pad[ep,st]=3\n",
    "\n",
    "                if line[1][5:-1]=='HOLD': st_types[ep,st]=1\n",
    "                elif line[1][5:-1]=='PASS': st_types[ep,st]=2\n",
    "                elif line[1][5:-1]=='RELEASE': st_types[ep,st]=3\n",
    "\n",
    "                if line[3]=='REP_2': st_rep[ep,st]=2\n",
    "                elif line[3]=='REP_5': st_rep[ep,st]=5\n",
    "                elif line[3]=='REP_10': st_rep[ep,st]=10\n",
    "\n",
    "                if line[5]=='ISI_10': st_isi[ep,st]=10\n",
    "                elif line[5]=='ISI_20': st_isi[ep,st]=20\n",
    "                elif line[5]=='ISI_50': st_isi[ep,st]=50\n",
    "                    \n",
    "                if line[7]=='Normal': st_ctrl[ep,st]=10\n",
    "                elif line[7][0:5]=='Ctrl1': st_ctrl[ep,st]=1\n",
    "                elif line[7][0:5]=='Ctrl2': st_ctrl[ep,st]=2\n",
    "                elif line[7][0:5]=='Ctrl3': st_ctrl[ep,st]=3\n",
    "                elif line[7][0:5]=='Ctrl4': st_ctrl[ep,st]=4\n",
    "\n",
    "                st+=1\n",
    "                if st%stims_ep==0:\n",
    "                    st=0\n",
    "                    ep+=1\n",
    "\n",
    "    Stim_dict = AttrDict({'st_logic':st_logic, 'episodes': episodes  ,'stims_ep':stims_ep  ,'st_times': starts})\n",
    "    Stim_dict.update({'st_isi':st_isi,'st_rep':st_rep,'st_types':st_types,'st_ctrl': st_ctrl,'st_pad':st_pad})\n",
    "    \n",
    "    return Stim_dict\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# BUILD HIST DICTIONARY\n",
    "#----------------------------------------------------------------------------------------\n",
    "import copy as cp\n",
    "\n",
    "def build_hist_dict():\n",
    "    isis = [10,20,50]\n",
    "    reps = [2,5,10]\n",
    "    pads = ['ARC','ROW','PAD']\n",
    "    types = ['HOLD','PASS','RELEASE']\n",
    "    \n",
    "    Isis ={}\n",
    "    for i in isis:\n",
    "        Isis[i]= []\n",
    "    \n",
    "    Reps ={}\n",
    "    for r in reps:\n",
    "        Reps[r] = cp.deepcopy(Isis)\n",
    "    \n",
    "    Pads = {}\n",
    "    for p in pads:\n",
    "        Pads[p] = cp.deepcopy(Reps)\n",
    "    \n",
    "    Types = {}\n",
    "    for t in types:\n",
    "        Types[t] = cp.deepcopy(Pads)\n",
    "    \n",
    "    Normal = cp.deepcopy(Types)\n",
    "    Ctrl1 = cp.deepcopy(Types)\n",
    "    Ctrl2 = cp.deepcopy(Types)\n",
    "    Ctrl3 = cp.deepcopy(Types)\n",
    "    Ctrl4 = cp.deepcopy(Types)\n",
    "    \n",
    "    counts_n = cp.deepcopy(Normal)\n",
    "    counts_c1 = cp.deepcopy(Normal)\n",
    "    counts_c2 = cp.deepcopy(Normal)\n",
    "    counts_c3 = cp.deepcopy(Normal)\n",
    "    counts_c4 = cp.deepcopy(Normal)\n",
    "    \n",
    "    Counts ={}\n",
    "    Counts['Normal'] = counts_n\n",
    "    Counts['Ctrl1'] = counts_c1\n",
    "    Counts['Ctrl2'] = counts_c2\n",
    "    Counts['Ctrl3'] = counts_c3\n",
    "    Counts['Ctrl4'] = counts_c4\n",
    "    Counts['Blank'] = []\n",
    "    \n",
    "    hist_logic = 'Type x Pad x Rep x Isi'\n",
    "    hist = AttrDict({ 'Blank' :[],  'Normal': Normal, 'Ctrl1':Ctrl1 , 'Ctrl2':Ctrl2 , 'Ctrl3': Ctrl3, 'Ctrl4': Ctrl4 , 'hist_logic': hist_logic, 'Counts':Counts})\n",
    "\n",
    "    return hist\n",
    "    \n",
    "#----------------------------------------------------------------------------------------\n",
    "# READKWIKINFO\n",
    "#----------------------------------------------------------------------------------------\n",
    "# We read the data of the output from klusterkwik: spike times and cluster-number of each\n",
    "# cluster-number is in klustaviewa series (can be as high as 130 e.g.)\n",
    "# Grupete stands for cluster groups! 2: good clusters, 1: multiunits, 0: unsorted, 3: noise\n",
    "def readkwikinfo(kwik, grupete=2):\n",
    "    model = KwikModel(kwik) # load kwik model from file\n",
    "    spiketimes = model.spike_times # extract the absolute spike times\n",
    "    clusters = model.cluster_groups # extract the cluster names\n",
    "    sample_rate = model.sample_rate # extract sampling freq\n",
    "    \n",
    "    spikedata = {} # initialise dictionary\n",
    "    for cluster in clusters.keys():\n",
    "        clustergroup = clusters[cluster]\n",
    "        if clustergroup==grupete: # only look at specified type of cluster, 0 = noise, 1 = MUA, 2 = GOOD, 3 = unsorted\n",
    "            spiketimematrix = AttrDict({'spike_times': np.zeros(len(spiketimes[where(model.spike_clusters==cluster)]))})\n",
    "            spiketimematrix.spike_times = spiketimes[where(model.spike_clusters==cluster)]\n",
    "            spikedata[cluster] = spiketimematrix # data structure is a dictionary with attribute accessible spiketimes\n",
    "            # attribute accessible means that spikedata.spike_times works, normal dictionaries would be spikedata[spike_times]\n",
    "    \n",
    "    model.close()\n",
    "    \n",
    "    return spikedata, sample_rate\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# BUILDS PSTH\n",
    "#----------------------------------------------------------------------------------------\n",
    "def BuildPSTH(Stims, Spikes, sampling_freq, exp, meas):\n",
    "    \n",
    "    stimtimes = {}\n",
    "    stim_samp = 1/.0009997575757\n",
    "    # make an 'output dict'\n",
    "    # the PSTH will be built on -tbefore:tafter\n",
    "    PSTH_times = {}\n",
    "    \n",
    "    # Loop each neuron and get the spikes.\n",
    "    for neuron in list(Spikes.keys()): \n",
    "        codename = 'exp'+ str(exp) + '_' + str(meas) + '_c' + str(neuron)\n",
    "        psth = AttrDict({'clusnum': neuron,'exp' : int(exp) , 'meas': int(meas[1]) , 'shank': int(meas[3])})\n",
    "        psth.update(AttrDict({'psth_counts': [] , 'psth_times': []}))\n",
    "        \n",
    "        histo= build_hist_dict()\n",
    "        \n",
    "        #loop episodes and stims_per_episode, and populate the histograms\n",
    "        for ep in arange(Stims.episodes):\n",
    "            for se in arange(Stims.stims_ep):\n",
    "                code = str(int(Stims.st_ctrl[ep][se]))\n",
    "                c = Stims.st_logic.ctrl[code]\n",
    "                code = str(int(Stims.st_types[ep][se]))\n",
    "                if code=='BLANK':\n",
    "                    t_after=0.5\n",
    "                    hist[c].append (Spikes[(start <= spikes) * (spikes <= times + t_after)])\n",
    "                    hist['Counts'][c] += len(Spikes[(start <= spikes) * (spikes <= times + t_after)])\n",
    "                else:\n",
    "                    t = Stims.st_logic.types[code]\n",
    "                    code = str(int(Stims.st_pad[ep][se]))\n",
    "                    p = Stims.st_logic.pad[code]\n",
    "                    r = Stims.st_rep[ep][se]\n",
    "                    i = Stims.st_isi[ep][se]\n",
    "                    start = Stims.st_times[ep][se]\n",
    "                              \n",
    "                    t_after = 0.5*r\n",
    "                    histo[c][t][p][r][i].append(Spikes[(start <= spikes) * (spikes <= times + t_after)])\n",
    "                    histo['Counts'][c][t][p][r][i] += lenSpikes([(start <= spikes) * (spikes <= times + t_after)])\n",
    "                                                       \n",
    "        PSTH_times[codename] = hist\n",
    "       \n",
    "    return PSTH_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'histo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-384-dd88598d913e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhisto\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'histo' is not defined"
     ]
    }
   ],
   "source": [
    "histo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total episodes:  15\n",
      "Total stims per episode:  28\n",
      "dict_keys(['st_isi', 'episodes', 'st_rep', 'st_times', 'st_ctrl', 'st_type', 'stims_ep', 'st_pad', 'st_logic'])\n",
      "dict_keys(['Blank', 'Ctrl1', 'hist_logic', 'Ctrl2', 'Normal', 'Ctrl3', 'Ctrl4', 'Counts'])\n",
      "Type x Pad x Rep x Isi\n",
      "AttrDict({'types': {'pass': 2, 'hold': 1, 'release': 3}, 'pad': {'PAD': 3, 'ROW': 1, 'ARC': 2}, 'ctrl': {'Normal': 10, 'BLANK': 0, 'Ctrl2': 2, 'Ctrl1': 1, 'Ctrl3': 3}})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 28)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Folder = '/media/matias/DATA/WORKSPACE2/EXP_2'        \n",
    "stimfile = Folder +'/EXPECT-151217-stims-7.txt'   \n",
    "timefile = Folder +'/EXPECT-151217-times-7.txt'   \n",
    "\n",
    "Stims = build_dict_stim(stimfile, timefile)\n",
    "\n",
    "print(Stims.keys())\n",
    "\n",
    "h = build_hist_dict()\n",
    "\n",
    "print(h.keys())\n",
    "print(h.hist_logic)\n",
    "\n",
    "print(Stims.st_logic)\n",
    "\n",
    "Stims.st_rep.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Files and Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this cell you put all the information to make the code portable from computer to computer\n",
    "# You have to place all the file names and experiments, then you loop whichever you want to analyse\n",
    "#--------------------------------------------------------------------------------\n",
    "#Experiment numbers\n",
    "ExpeNum = [1,2]\n",
    "#--------------------------------------------------------------------------------\n",
    "#Folders for measurements and experiments (this is how we separate shanks in folders for individual analyses)\n",
    "m164 = ['m1s'+str(s) for s in arange(8)+1]\n",
    "m264 = ['m2s'+str(s) for s in arange(8)+1]\n",
    "m364 = ['m3s'+str(s) for s in arange(8)+1]\n",
    "m464 = ['m4s'+str(s) for s in arange(8)+1]\n",
    "m564 = ['m5s'+str(s) for s in arange(8)+1]\n",
    "m664 = ['m6s'+str(s) for s in arange(8)+1]\n",
    "m764 = ['m7s'+str(s) for s in arange(8)+1]\n",
    "m864 = ['m8s'+str(s) for s in arange(8)+1]\n",
    "m964 = ['m9s'+str(s) for s in arange(8)+1]\n",
    "m1064 = ['m10s'+str(s) for s in arange(8)+1]\n",
    "\n",
    "M = [m164,m264,m364,m464,m564,m664,m764,m864,m964,m1064]\n",
    "\n",
    "shanks = ['_ele01_ele08.kwik',\n",
    "          '_ele09_ele16.kwik',\n",
    "          '_ele17_ele24.kwik',\n",
    "          '_ele25_ele32.kwik',\n",
    "          '_ele33_ele40.kwik',\n",
    "          '_ele41_ele48.kwik',\n",
    "          '_ele49_ele56.kwik',\n",
    "          '_ele57_ele64.kwik']\n",
    "#--------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------\n",
    "#Kwik files    \n",
    "base = {}\n",
    "files = {}\n",
    "#--------------------------------------------------------------------------------\n",
    "exp = 1\n",
    "base[exp] = ['EXPECT-151029-'+str(i) for i in arange(10)+1]\n",
    "files[exp] ={}\n",
    "for reps in arange(10):\n",
    "    files[exp][reps+1] = [ base[exp][reps]+shanks[i] for i in arange(8)]\n",
    "#--------------------------------------------------------------------------------\n",
    "exp = 2\n",
    "base[exp] = ['EXPECT-151217-'+str(i) for i in arange(10)+1]\n",
    "files[exp] ={}\n",
    "for reps in arange(7):\n",
    "    files[exp][reps+1] = [ base[exp][reps]+shanks[i] for i in arange(8)]\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Here I create my dictionary of experiments\n",
    "Expe={}\n",
    "for num in ExpeNum: \n",
    "    Expe[num] = dict()\n",
    "#---------------------------------------\n",
    "stimfiles = {}\n",
    "timefiles = {}\n",
    "eptimefiles = {}\n",
    "\n",
    "exp =1\n",
    "m=0\n",
    "for Meas in M[0:10]:\n",
    "    i=0\n",
    "    for meas in Meas:\n",
    "        Expe[exp][meas] = files[exp][m+1][i]\n",
    "        i+=1\n",
    "    m+=1\n",
    "exp=2\n",
    "m=0\n",
    "for Meas in M[0:7]:\n",
    "    i=0\n",
    "    for meas in Meas:\n",
    "        Expe[exp][meas] = files[exp][m+1][i]\n",
    "        i+=1\n",
    "    m+=1\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Stim files\n",
    "for exp in ExpeNum:\n",
    "    stimfiles[exp] = [base[exp][rep-1][:-1] + 'stims-' + str(rep) + '.txt' for rep in files[1]]\n",
    "    timefiles[exp] = [base[exp][rep-1][:-1] + 'times-' + str(rep) + '.txt' for rep in files[1]]\n",
    "    eptimefiles[exp] = [base[exp][rep-1][:-1] + 'ep_times-' + str(rep) + '.txt' for rep in files[1]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and load data files from experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "group: 2\n",
      "m7s1\n",
      "Total episodes:  15\n",
      "Total stims per episode:  28\n",
      "   building psths\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-399-a6c5687ff5c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'   building psths'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[0mPSTH_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBuildPSTH\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpikes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampling_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'   saving'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-398-25faa7c05cd4>\u001b[0m in \u001b[0;36mBuildPSTH\u001b[1;34m(Stims, Spikes, sampling_freq, exp, meas)\u001b[0m\n\u001b[0;32m    227\u001b[0m                     \u001b[0mhist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Counts'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSpikes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mspikes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mspikes\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mtimes\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mt_after\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m                     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStims\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_logic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m                     \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStims\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_pad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mep\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStims\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_logic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '0'"
     ]
    }
   ],
   "source": [
    "global binname, textname\n",
    "#---------------------------------------------------------------------------------------\n",
    "SelExp = [2]                         #select experiment numbers!\n",
    "grupete = [2]   #select cluster groups! 2 for good clusters 1 for multiunits, 3 for unsorted\n",
    "\n",
    "#select measurement and/or shanks!\n",
    "Measurements = m764[0:1]           #['m1s1']#['m3s1','m3s3']#m12[-4:]#['m1s1','m1s2','m1s3','m1s4']   \n",
    "\n",
    "rootF = '/media/matias/DATA/WORKSPACE2/'    \n",
    "\n",
    "dirs =[]\n",
    "#--------------------------------------------------------------------------------\n",
    "# Loop Experiments\n",
    "#--------------------------------------------------------------------------------\n",
    "last_exp=0     #we use this to load stim only when we change experiment\n",
    "for expe in SelExp:\n",
    "    \n",
    "    PSTHdata = {}\n",
    "    PSTH_spikes_counts = {}\n",
    "    \n",
    "    #Measurements = sorted(Expe[expe])                         #uncommento to select all\n",
    "    print(expe)\n",
    "   \n",
    "    last_meas =0   #we use this to find when we change measurement to load Vtag and stim again\n",
    "    \n",
    "    #--------------------------------------------------------------------------------\n",
    "    #loop goodunits, multiunits, unsorted...\n",
    "    for group in grupete:   #2 for good clusters 1 for multiunits 3 for unsorted\n",
    "        #folder names\n",
    "        if group ==3:\n",
    "            dirs  = [rootF + 'OUTPUT/EXP_'+str(expe)]\n",
    "        if group ==2:\n",
    "            dirs  = [rootF + 'OUTPUT/EXP_'+str(expe)]\n",
    "        if group ==1:\n",
    "            dirs  = [rootF + 'OUTPUT/EXP_'+str(expe)]\n",
    "        #--------------------------------------------------------------------------------\n",
    "        #create output folders\n",
    "        for dir in dirs:\n",
    "            if not os.path.exists(dir):\n",
    "                os.makedirs(dir) \n",
    "        dire = dirs[0] +'/'\n",
    "        titles = 'Exp'+ str(expe) + '_Meas_' + meas[1] + '_Shank_' + meas[3]\n",
    "        #--------------------------------------------------------------------------------\n",
    "        print('group:', group)\n",
    "        #--------------------------------------------------------------------------------\n",
    "        #loop measurements and shanks\n",
    "        #Measurements = sorted((Expe[expe]))\n",
    "        \n",
    "        for meas in Measurements:           \n",
    "            print(meas)\n",
    "            current_meas = int(meas[1])   #measurement number\n",
    "            #---------------------------------------------------------------\n",
    "            #This is to account for diffrerent stims when looping diffrerent experiments\n",
    "            if current_meas!=last_meas:\n",
    "                stimfile = rootF + 'EXP_' + str(expe) + '/' + stimfiles[expe][current_meas-1]\n",
    "                timefile = rootF + 'EXP_' + str(expe) + '/' +timefiles[expe][current_meas-1]\n",
    "                epfile = rootF + 'EXP_' + str(expe) + '/' +eptimefiles[expe][current_meas-1]\n",
    "                \n",
    "                Stims = build_dict_stim(stimfile, timefile, epfile)\n",
    "          \n",
    "            \n",
    "            #select datafile\n",
    "            sp_file = rootF + 'EXP_' + str(expe) +'/Spike_Sort/'+ meas +'/'+ Expe[expe][meas]\n",
    "            #load datafile\n",
    "            Spikes, sampling_freq = readkwikinfo(sp_file, group)  \n",
    "                    \n",
    "            if len(Spikes.keys())>0:                              #do only if there are clusters\n",
    "                #Build PSTHs\n",
    "                print('   building psths')\n",
    "    \n",
    "                PSTH_data = BuildPSTH(Stims, Spikes, sampling_freq, exp, meas) \n",
    "               \n",
    "    print('   saving')\n",
    "    if group == 2:\n",
    "        filesave =rootF +'Expect_git/data/'+'psthdata' + str(expe)\n",
    "    else:\n",
    "        filesave =rootF +'S2_git/data/'+ 'psthdataMultiR' + str(expe)\n",
    "        \n",
    "    #save_obj(PSTHdata,filesave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-398-25faa7c05cd4>\u001b[0m(229)\u001b[0;36mBuildPSTH\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    228 \u001b[1;33m                \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 229 \u001b[1;33m                    \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStims\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_logic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    230 \u001b[1;33m                    \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStims\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_pad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mep\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> Stims.st_logic.types\n",
      "AttrDict({'3': 'release', '1': 'hold', '2': 'pass'})\n",
      "ipdb> p\n",
      "*** SyntaxError: unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.hist>"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['psth_counts', 'meas', 'psth_length', 'clusnum', 'psth_times', 'exp', 'shank'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filesave\n",
    "\n",
    "sorted(list(PSTHdata.keys()))\n",
    "PSTHdata['exp20_m1s1_c29'].keys()\n",
    "\n",
    "data = rootF +'S2_git/data/'+'psthdata' + str(22)\n",
    "\n",
    "a = load_obj(data)\n",
    "\n",
    "a['exp22_m3s4_c1138'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#update spiketimes to wavedataAll\n",
    "SelExp = [20] #[22,24,26,27,28,29,30,31,32] #Expe                                        #select experiment numbers!\n",
    "\n",
    "Folder = '/home/matias/WORKSPACE/S2_git/data'    \n",
    "\n",
    "for e in SelExp:\n",
    "\n",
    "    data = Folder +'/wavedata'+ str(e)\n",
    "    wavedata = load_obj(data)\n",
    "\n",
    "    idx = list(wavedata.keys())\n",
    "\n",
    "    datapsth = Folder +'/psthdata' + str(e)\n",
    "    psthdata = load_obj(datapsth)\n",
    "\n",
    "\n",
    "    for n in idx:\n",
    "        wavedata[n].update(psthdata[n])    \n",
    "            \n",
    "    data = Folder +'data/datamix' + str(e)\n",
    "\n",
    "    save_obj(wavedata, data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = list(PSTHdata.keys())\n",
    "PSTHdata[idx[0]].keys()\n",
    "#PSTHdata[idx[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Spikes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PSTHdata[idx[0]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
